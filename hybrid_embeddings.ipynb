{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie & Game Embedding 결합 및 Latent Transformation\n",
        "1. 영화 & 게임 임베딩(.npy) 불러오기\n",
        "2. TruncatedSVD로 차원 축소\n",
        "3. MLP를 이용한 latent embedding 생성 (128차원)\n",
        "4. 사용자 latent embedding placeholder 생성\n",
        "5. 영화 + 게임 + 사용자 embedding 결합\n",
        "6. 추천 시스템에서 바로 사용할 수 있는 구조 생성\n",
        "\n",
        "* 현재 user latent는 랜덤 placeholder → 실제 NCF 학습 후 교체 필요\n",
        "\n",
        "* embedding 수는 min_len 기준으로 맞춤 → 전체 영화/게임 수와 다를 수 있음"
      ],
      "metadata": {
        "id": "-ISBiO3kL-CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# 0. 환경 준비\n",
        "# ======================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ======================================================\n",
        "# 1. 영화 & 게임 임베딩 불러오기\n",
        "# ======================================================\n",
        "movie_path = '/content/drive/MyDrive/2025Bigdata/movie_dataset/hybrid_movie_embeddings.npy'\n",
        "game_path  = '/content/drive/MyDrive/2025Bigdata/game_dataset/hybrid_game_embeddings_BERT_final.npy'\n",
        "movies_csv = '/content/drive/MyDrive/2025Bigdata/movie_dataset/movies.csv'\n",
        "games_csv  = '/content/drive/MyDrive/2025Bigdata/game_dataset/cleaned_games.csv'\n",
        "\n",
        "movie_embeddings = np.load(movie_path)\n",
        "game_embeddings  = np.load(game_path)\n",
        "\n",
        "movie_df = pd.read_csv(movies_csv)\n",
        "game_df  = pd.read_csv(games_csv)\n",
        "\n",
        "movie_titles = movie_df['title'].tolist()\n",
        "game_titles  = game_df['title'].tolist()\n",
        "\n",
        "# 길이 맞추기\n",
        "min_len = min(len(movie_embeddings), len(game_embeddings))\n",
        "movie_embeddings = movie_embeddings[:min_len]\n",
        "game_embeddings  = game_embeddings[:min_len]\n",
        "\n",
        "# ======================================================\n",
        "# 2. 차원 축소 (TruncatedSVD)\n",
        "# ======================================================\n",
        "target_dim = 512\n",
        "svd_movie = TruncatedSVD(n_components=target_dim, random_state=42)\n",
        "svd_game  = TruncatedSVD(n_components=target_dim, random_state=42)\n",
        "\n",
        "movie_reduced = svd_movie.fit_transform(movie_embeddings)\n",
        "game_reduced  = svd_game.fit_transform(game_embeddings)\n",
        "\n",
        "# ======================================================\n",
        "# 3. Weighted sum hybrid embedding (선택 사항)\n",
        "# ======================================================\n",
        "alpha = 0.5\n",
        "hybrid_embeddings = alpha * movie_reduced + (1-alpha) * game_reduced\n",
        "\n",
        "# ======================================================\n",
        "# 4. MLP latent embedding 생성\n",
        "# ======================================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, latent_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "mlp = SimpleMLP(input_dim=target_dim, latent_dim=128).to(DEVICE)\n",
        "mlp.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    movie_tensor = torch.tensor(movie_reduced, dtype=torch.float32).to(DEVICE)\n",
        "    game_tensor  = torch.tensor(game_reduced, dtype=torch.float32).to(DEVICE)\n",
        "    movie_latent = mlp(movie_tensor).cpu().numpy()\n",
        "    game_latent  = mlp(game_tensor).cpu().numpy()\n",
        "\n",
        "# ======================================================\n",
        "# 5. User latent embedding 준비 (placeholder)\n",
        "# ======================================================\n",
        "num_users = 610\n",
        "user_latent = np.random.rand(num_users, 128)  # 실제 NCF 학습 후 교체 가능\n",
        "\n",
        "# ======================================================\n",
        "# 6. 전체 embedding 결합\n",
        "# ======================================================\n",
        "latent_embeddings = np.vstack([movie_latent, game_latent])\n",
        "final_embeddings = np.vstack([latent_embeddings, user_latent])\n",
        "\n",
        "# item types & titles mapping\n",
        "item_types = ['movie']*movie_latent.shape[0] + ['game']*game_latent.shape[0] + ['user']*user_latent.shape[0]\n",
        "item_titles = movie_titles[:min_len] + game_titles[:min_len] + [f\"user_{i}\" for i in range(num_users)]\n",
        "\n",
        "print(\"Final embeddings shape:\", final_embeddings.shape)\n",
        "print(\"Item types length:\", len(item_types))\n",
        "print(\"Item titles length:\", len(item_titles))\n",
        "\n",
        "# ======================================================\n",
        "# 7. 추천용 similarity 예시 (user 0 기준 top 5 아이템)\n",
        "# ======================================================\n",
        "user_index = -1  # 예: 마지막 user\n",
        "user_vec = final_embeddings[user_index].reshape(1, -1)\n",
        "item_vecs = final_embeddings[:movie_latent.shape[0]+game_latent.shape[0]]\n",
        "\n",
        "sim_scores = cosine_similarity(user_vec, item_vecs).flatten()\n",
        "top_indices = sim_scores.argsort()[::-1][:5]\n",
        "\n",
        "for idx in top_indices:\n",
        "    print(item_titles[idx], item_types[idx], sim_scores[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt9xTCOlZOCx",
        "outputId": "b315b04c-d239-4b93-b1ba-c915ba87fd3f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final embeddings shape: (10610, 128)\n",
            "Item types length: 10610\n",
            "Item titles length: 10610\n",
            "Bounce (2000) movie 0.06409394824613292\n",
            "Dead Man (1995) movie 0.06374894218476801\n",
            "Girl 6 (1996) movie 0.05706766935992481\n",
            "Crash (1996) movie 0.05286406158202327\n",
            "2010: The Year We Make Contact (1984) movie 0.05226071645795847\n"
          ]
        }
      ]
    }
  ]
}