{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFIMTjjg2S4k",
        "outputId": "c72598a1-6686-4e95-9595-6369a65924f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPciHhqN620T",
        "outputId": "8a3f45e5-b956-4702-bcca-9d57639c8af0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANyBiNy11f8v",
        "outputId": "385287b2-05a6-4372-8676-a012df3618ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch Device Set: cuda\n",
            "\n",
            "✅ Game data loaded successfully: /content/drive/MyDrive/bigData/game_recommend_system/game_dataset/cleaned_games.csv\n",
            "\n",
            "--- 1. 스토리라인 BERT 임베딩 시작 (GPU 권장) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BERT Embedding: 100%|██████████| 157/157 [02:35<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Storyline Embeddings Shape: (5000, 768)\n",
            "\n",
            "--- 2. 장르 TF-IDF 임베딩 시작 ---\n",
            "Genre TF-IDF Matrix Shape: (5000, 21)\n",
            "\n",
            "=======================================================\n",
            "✨ Step 3: BERT 기반 게임 임베딩 생성 완료 ✨\n",
            "총 임베딩 차원: 789 차원\n",
            "저장 파일: hybrid_game_embeddings_BERT_final.npy\n",
            "=======================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from tqdm import tqdm # 진행 상황 확인용\n",
        "\n",
        "# ⚠️ BERT 관련 라이브러리 (Colab에서 설치 필수)\n",
        "# !pip install transformers torch\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "    # GPU (CUDA) 사용 여부 확인 및 장치 설정\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"✅ PyTorch Device Set: {DEVICE}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"FATAL ERROR: torch 또는 transformers 라이브러리가 설치되지 않았습니다.\")\n",
        "    print(\"Colab에서 !pip install transformers torch 를 실행하세요.\")\n",
        "    exit()\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. BERT 임베딩 함수 정의 (사용자 제공 구조 + Device 적용)\n",
        "# ----------------------------------------------------\n",
        "def get_bert_embeddings(texts, model_name='bert-base-uncased', max_len=256):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
        "    model.eval() # 추론 모드 설정\n",
        "\n",
        "    EMBEDDING_DIM = 768\n",
        "    all_embeddings = []\n",
        "\n",
        "    # 데이터를 배치(Batch) 단위로 처리하여 GPU 메모리 사용 효율을 높입니다.\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"BERT Embedding\"):\n",
        "        batch_texts = texts[i:i + BATCH_SIZE]\n",
        "\n",
        "        # 텍스트를 토큰화 및 패딩\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_len\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # [CLS] 토큰 벡터 추출 (문장 전체의 의미를 압축한 벡터)\n",
        "        # 텐서를 CPU로 옮긴 후 NumPy로 변환\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. 메인 실행 파이프라인\n",
        "# ----------------------------------------------------\n",
        "\n",
        "GAME_FILE = ('/content/drive/MyDrive/bigData/game_recommend_system/game_dataset/cleaned_games.csv')\n",
        "\n",
        "try:\n",
        "    game_df = pd.read_csv(GAME_FILE)\n",
        "    print(f\"\\n✅ Game data loaded successfully: {GAME_FILE}\")\n",
        "except Exception as e:\n",
        "    print(f\"FATAL ERROR: Game data file not found. {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2a. 데이터 전처리 (결측값 처리) ---\n",
        "game_df['genres'] = game_df['genres'].fillna('')\n",
        "# 스토리라인이 너무 길 경우 BERT의 max_len(512)을 초과할 수 있으므로,\n",
        "# 너무 긴 텍스트는 임의의 짧은 텍스트로 대체합니다. (실제 BERT가 truncation 함)\n",
        "game_df['storyline'] = game_df['storyline'].fillna('No Storyline Available.')\n",
        "\n",
        "\n",
        "# --- 2b. 스토리라인 BERT 임베딩 생성 (핵심) ---\n",
        "print(\"\\n--- 1. 스토리라인 BERT 임베딩 시작 (GPU 권장) ---\")\n",
        "storyline_embeddings_bert = get_bert_embeddings(game_df['storyline'].tolist(), max_len=512)\n",
        "print(f\"BERT Storyline Embeddings Shape: {storyline_embeddings_bert.shape}\")\n",
        "\n",
        "\n",
        "# --- 2c. 장르 TF-IDF 임베딩 생성 (보조 특징) ---\n",
        "print(\"\\n--- 2. 장르 TF-IDF 임베딩 시작 ---\")\n",
        "genre_tfidf = TfidfVectorizer()\n",
        "genre_matrix = genre_tfidf.fit_transform(game_df['genres']).toarray()\n",
        "print(f\"Genre TF-IDF Matrix Shape: {genre_matrix.shape}\")\n",
        "\n",
        "\n",
        "# --- 2d. 최종 게임 임베딩 하이브리드화 ---\n",
        "# BERT 임베딩(Dense)과 장르 TF-IDF 벡터(Dense)를 수평으로 결합합니다.\n",
        "hybrid_game_embeddings = np.hstack([storyline_embeddings_bert, genre_matrix])\n",
        "\n",
        "\n",
        "# 3. 최종 결과 저장\n",
        "output_filename = 'hybrid_game_embeddings_BERT_final.npy'\n",
        "np.save(output_filename, hybrid_game_embeddings)\n",
        "np.save('final_game_ids.npy', game_df['game_id'].values)\n",
        "\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"✨ Step 3: BERT 기반 게임 임베딩 생성 완료 ✨\")\n",
        "print(f\"총 임베딩 차원: {hybrid_game_embeddings.shape[1]} 차원\")\n",
        "print(f\"저장 파일: {output_filename}\")\n",
        "print(\"=======================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/hybrid_game_embeddings_BERT_final.npy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "R211lj7BHhoM",
        "outputId": "b0222538-2cfa-4274-b3ca-40793291337b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93e0ed8d-36b9-400f-92d7-2b218f70d7ae\", \"hybrid_game_embeddings_BERT_final.npy\", 31560128)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}